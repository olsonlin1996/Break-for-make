import os
import torch
from diffusers import DiffusionPipeline, AutoencoderKL
from safetensors.torch import load_file

# 1) Base model
base_model_id = "stabilityai/stable-diffusion-xl-base-1.0"

# 2) LoRA：指向你 second stage 產出的權重檔
# 例如：.../outputs/second_stage_run_XXXXXXXX_XXXXXX/yarn__elephant/pytorch_lora_weights.safetensors
#lora_path = "/home/cglab/project/olson/Break-for-make/outputs/second_stage_run_20260120_163109/glass__corgi/pytorch_lora_weights.safetensors"
lora_path = "/home/cglab/project/olson/Break-for-make/outputs/second_stage_run_20260120_163109/yarn__corgi/pytorch_lora_weights.safetensors"

# 3) Output：一定要是「檔案路徑」
#output_path = "/home/cglab/project/olson/Break-for-make/outputs/infer/glass__corgi_seed77.png"
output_path = "/home/cglab/project/olson/Break-for-make/outputs/infer/yarn__corgi_seed77.png"

# 4) Prompt：沿用你 second stage 的 token 慣例
# 例：content=corgi, style=glass
#prompt = "a photo of snq corgi, w@z crafted from clean glass, transparent material, glossy reflections, refraction"
prompt = "a photo of snq corgi, w@z yarn art style, knitted or crochet texture, wool fibers, handcrafted"

seed = 77
num_steps = 25

# dtype：你現在推論用 fp16 就維持 float16；若要 bf16 改 torch.bfloat16
dtype = torch.bfloat16

# --- build pipeline ---
vae = AutoencoderKL.from_pretrained("madebyollin/sdxl-vae-fp16-fix", torch_dtype=dtype)

pipe = DiffusionPipeline.from_pretrained(
    base_model_id,
    vae=vae,
    torch_dtype=dtype,
    use_safetensors=True,
).to("cuda")

def generate_and_save(tag: str, out_path: str):
    os.makedirs(os.path.dirname(out_path), exist_ok=True)

    # 重要：每次呼叫都重新 seed 一個新的 generator，確保可重現
    generator = torch.Generator(device="cuda").manual_seed(seed)

    img = pipe(
        prompt,
        num_inference_steps=num_steps,
        guidance_scale=5.0,
        generator=generator,
    ).images[0]

    img.save(out_path)
    print(f"[{tag}] saved: {out_path}")

# 1) 先跑「Base（不載 LoRA）」
output_base = output_path.replace(".png", "_BASE.png")
generate_and_save("BASE", output_base)

# 2) 再載入 LoRA，跑「+LoRA」
lora_state_dict = load_file(lora_path)
pipe.load_lora_weights(lora_state_dict)

output_lora = output_path.replace(".png", "_LORA.png")
# 建議明確指定 guidance_scale，確保可比
# 你也可以把 guidance_scale 放進 generate_and_save 參數
generate_and_save("LORA", output_lora)
